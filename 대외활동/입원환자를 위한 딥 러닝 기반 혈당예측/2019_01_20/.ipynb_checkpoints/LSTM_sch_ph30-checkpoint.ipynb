{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "trainData_in_list_len: 299\n",
      "trainData_out_list_len: 299\n",
      "testData_in_list_len: 38\n",
      "testData_out_list_len: 38\n",
      "WARNING:tensorflow:From <ipython-input-1-11afedfc2db5>:136: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:From /home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.0%\n",
      "0.33444816053511706%\n",
      "0.6688963210702341%\n",
      "1.0033444816053512%\n",
      "1.3377926421404682%\n",
      "1.6722408026755853%\n",
      "2.0066889632107023%\n",
      "2.341137123745819%\n",
      "2.6755852842809364%\n",
      "3.0100334448160537%\n",
      "3.3444816053511706%\n",
      "3.678929765886288%\n",
      "4.013377926421405%\n",
      "4.3478260869565215%\n",
      "4.682274247491638%\n",
      "5.016722408026756%\n",
      "5.351170568561873%\n",
      "5.68561872909699%\n",
      "6.0200668896321075%\n",
      "6.354515050167224%\n",
      "6.688963210702341%\n",
      "7.023411371237458%\n",
      "7.357859531772576%\n",
      "7.6923076923076925%\n",
      "8.02675585284281%\n",
      "8.361204013377927%\n",
      "8.695652173913043%\n",
      "9.03010033444816%\n",
      "9.364548494983277%\n",
      "9.698996655518394%\n",
      "10.033444816053512%\n",
      "10.367892976588628%\n",
      "10.702341137123746%\n",
      "11.036789297658862%\n",
      "11.37123745819398%\n",
      "11.705685618729097%\n",
      "12.040133779264215%\n",
      "12.37458193979933%\n",
      "12.709030100334449%\n",
      "13.043478260869565%\n",
      "13.377926421404682%\n",
      "13.712374581939798%\n",
      "14.046822742474916%\n",
      "14.381270903010032%\n",
      "14.715719063545151%\n",
      "15.050167224080269%\n",
      "15.384615384615385%\n",
      "15.719063545150503%\n",
      "16.05351170568562%\n",
      "16.387959866220736%\n",
      "16.722408026755854%\n",
      "17.05685618729097%\n",
      "17.391304347826086%\n",
      "17.725752508361204%\n",
      "18.06020066889632%\n",
      "18.394648829431436%\n",
      "18.729096989966553%\n",
      "19.063545150501675%\n",
      "19.39799331103679%\n",
      "19.732441471571907%\n",
      "20.066889632107024%\n",
      "20.401337792642142%\n",
      "20.735785953177256%\n",
      "21.070234113712374%\n",
      "21.40468227424749%\n",
      "21.73913043478261%\n",
      "22.073578595317723%\n",
      "22.40802675585284%\n",
      "22.74247491638796%\n",
      "23.076923076923077%\n",
      "23.411371237458194%\n",
      "23.745819397993312%\n",
      "24.08026755852843%\n",
      "24.414715719063544%\n",
      "24.74916387959866%\n",
      "25.08361204013378%\n",
      "25.418060200668897%\n",
      "25.75250836120401%\n",
      "26.08695652173913%\n",
      "26.421404682274247%\n",
      "26.755852842809364%\n",
      "27.09030100334448%\n",
      "27.424749163879596%\n",
      "27.759197324414714%\n",
      "28.093645484949832%\n",
      "28.428093645484946%\n",
      "28.762541806020064%\n",
      "29.09698996655518%\n",
      "29.431438127090303%\n",
      "29.76588628762542%\n",
      "30.100334448160538%\n",
      "30.434782608695656%\n",
      "30.76923076923077%\n",
      "31.103678929765888%\n",
      "31.438127090301005%\n",
      "31.77257525083612%\n",
      "32.10702341137124%\n",
      "32.441471571906355%\n",
      "32.77591973244147%\n",
      "33.11036789297659%\n",
      "33.44481605351171%\n",
      "33.77926421404682%\n",
      "34.11371237458194%\n",
      "34.448160535117054%\n",
      "34.78260869565217%\n",
      "35.11705685618729%\n",
      "35.45150501672241%\n",
      "35.785953177257525%\n",
      "36.12040133779264%\n",
      "36.45484949832776%\n",
      "36.78929765886287%\n",
      "37.12374581939799%\n",
      "37.45819397993311%\n",
      "37.79264214046823%\n",
      "38.12709030100335%\n",
      "38.46153846153847%\n",
      "38.79598662207358%\n",
      "39.130434782608695%\n",
      "39.46488294314381%\n",
      "39.79933110367893%\n",
      "40.13377926421405%\n",
      "40.468227424749166%\n",
      "40.802675585284284%\n",
      "41.1371237458194%\n",
      "41.47157190635451%\n",
      "41.80602006688963%\n",
      "42.14046822742475%\n",
      "42.474916387959865%\n",
      "42.80936454849498%\n",
      "43.1438127090301%\n",
      "43.47826086956522%\n",
      "43.812709030100336%\n",
      "44.14715719063545%\n",
      "44.481605351170565%\n",
      "44.81605351170568%\n",
      "45.1505016722408%\n",
      "45.48494983277592%\n",
      "45.819397993311036%\n",
      "46.15384615384615%\n",
      "46.48829431438127%\n",
      "46.82274247491639%\n",
      "47.15719063545151%\n",
      "47.491638795986624%\n",
      "47.82608695652174%\n",
      "48.16053511705686%\n",
      "48.49498327759198%\n",
      "48.82943143812709%\n",
      "49.163879598662206%\n",
      "49.49832775919732%\n",
      "49.83277591973244%\n",
      "50.16722408026756%\n",
      "50.50167224080268%\n",
      "50.836120401337794%\n",
      "51.17056856187291%\n",
      "51.50501672240802%\n",
      "51.83946488294314%\n",
      "52.17391304347826%\n",
      "52.508361204013376%\n",
      "52.84280936454849%\n",
      "53.17725752508361%\n",
      "53.51170568561873%\n",
      "53.84615384615385%\n",
      "54.18060200668896%\n",
      "54.515050167224075%\n",
      "54.84949832775919%\n",
      "55.18394648829431%\n",
      "55.51839464882943%\n",
      "55.852842809364546%\n",
      "56.187290969899664%\n",
      "56.52173913043478%\n",
      "56.85618729096989%\n",
      "57.19063545150501%\n",
      "57.52508361204013%\n",
      "57.859531772575245%\n",
      "58.19397993311036%\n",
      "58.52842809364549%\n",
      "58.862876254180605%\n",
      "59.19732441471572%\n",
      "59.53177257525084%\n",
      "59.86622073578596%\n",
      "60.200668896321076%\n",
      "60.535117056856194%\n",
      "60.86956521739131%\n",
      "61.20401337792642%\n",
      "61.53846153846154%\n",
      "61.87290969899666%\n",
      "62.207357859531776%\n",
      "62.54180602006689%\n",
      "62.87625418060201%\n",
      "63.21070234113713%\n",
      "63.54515050167224%\n",
      "63.87959866220736%\n",
      "64.21404682274247%\n",
      "64.54849498327759%\n",
      "64.88294314381271%\n",
      "65.21739130434783%\n",
      "65.55183946488295%\n",
      "65.88628762541806%\n",
      "66.22073578595318%\n",
      "66.5551839464883%\n",
      "66.88963210702342%\n",
      "67.22408026755853%\n",
      "67.55852842809364%\n",
      "67.89297658862876%\n",
      "68.22742474916387%\n",
      "68.56187290969899%\n",
      "68.89632107023411%\n",
      "69.23076923076923%\n",
      "69.56521739130434%\n",
      "69.89966555183946%\n",
      "70.23411371237458%\n",
      "70.5685618729097%\n",
      "70.90301003344482%\n",
      "71.23745819397993%\n",
      "71.57190635451505%\n",
      "71.90635451505017%\n",
      "72.24080267558529%\n",
      "72.5752508361204%\n",
      "72.90969899665552%\n",
      "73.24414715719062%\n",
      "73.57859531772574%\n",
      "73.91304347826086%\n",
      "74.24749163879598%\n",
      "74.5819397993311%\n",
      "74.91638795986621%\n",
      "75.25083612040135%\n",
      "75.58528428093646%\n",
      "75.91973244147158%\n",
      "76.2541806020067%\n",
      "76.58862876254182%\n",
      "76.92307692307693%\n",
      "77.25752508361204%\n",
      "77.59197324414716%\n",
      "77.92642140468227%\n",
      "78.26086956521739%\n",
      "78.59531772575251%\n",
      "78.92976588628763%\n",
      "79.26421404682274%\n",
      "79.59866220735786%\n",
      "79.93311036789298%\n",
      "80.2675585284281%\n",
      "80.60200668896321%\n",
      "80.93645484949833%\n",
      "81.27090301003345%\n",
      "81.60535117056857%\n",
      "81.93979933110369%\n",
      "82.2742474916388%\n",
      "82.6086956521739%\n",
      "82.94314381270902%\n",
      "83.27759197324414%\n",
      "83.61204013377926%\n",
      "83.94648829431438%\n",
      "84.2809364548495%\n",
      "84.61538461538461%\n",
      "84.94983277591973%\n",
      "85.28428093645485%\n",
      "85.61872909698997%\n",
      "85.95317725752508%\n",
      "86.2876254180602%\n",
      "86.62207357859532%\n",
      "86.95652173913044%\n",
      "87.29096989966555%\n",
      "87.62541806020067%\n",
      "87.95986622073578%\n",
      "88.2943143812709%\n",
      "88.62876254180601%\n",
      "88.96321070234113%\n",
      "89.29765886287625%\n",
      "89.63210702341136%\n",
      "89.96655518394648%\n",
      "90.3010033444816%\n",
      "90.63545150501672%\n",
      "90.96989966555184%\n",
      "91.30434782608695%\n",
      "91.63879598662207%\n",
      "91.9732441471572%\n",
      "92.3076923076923%\n",
      "92.64214046822742%\n",
      "92.97658862876254%\n",
      "93.31103678929766%\n",
      "93.64548494983278%\n",
      "93.9799331103679%\n",
      "94.31438127090301%\n",
      "94.64882943143813%\n",
      "94.98327759197325%\n",
      "95.31772575250837%\n",
      "95.65217391304348%\n",
      "95.9866220735786%\n",
      "96.32107023411372%\n",
      "96.65551839464884%\n",
      "96.98996655518395%\n",
      "97.32441471571906%\n",
      "97.65886287625418%\n",
      "97.9933110367893%\n",
      "98.32775919732441%\n",
      "98.66220735785953%\n",
      "98.99665551839465%\n",
      "99.33110367892976%\n",
      "99.66555183946488%\n",
      "DONE\n",
      "test-97635.csv\n",
      "test-319656.csv\n",
      "test-190432.csv\n",
      "test-317432.csv\n",
      "test-3814.csv\n",
      "test-279366.csv\n",
      "test-169576.csv\n",
      "test-301496.csv\n",
      "test-174473.csv\n",
      "test-338857.csv\n",
      "test-233593.csv\n",
      "test-337947.csv\n",
      "test-285833.csv\n",
      "test-212788.csv\n",
      "test-6570.csv\n",
      "test-246527.csv\n",
      "test-319119.csv\n",
      "test-266364.csv\n",
      "test-215405.csv\n",
      "test-230793.csv\n",
      "test-48857.csv\n",
      "test-258832.csv\n",
      "test-119357.csv\n",
      "test-212378.csv\n",
      "test-224260.csv\n",
      "test-272032.csv\n",
      "test-120666.csv\n",
      "test-231306.csv\n",
      "test-69435.csv\n",
      "test-81919.csv\n",
      "test-332243.csv\n",
      "test-21049.csv\n",
      "test-332256.csv\n",
      "test-72026.csv\n",
      "test-220747.csv\n",
      "test-181175.csv\n",
      "test-17771.csv\n",
      "test-291057.csv\n",
      "RMSE\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "NUM_EPOCHS = 300  # 반복 횟수\n",
    "chunk_size = 1  # 한 개 요소의 크기\n",
    "# n_chunks = 7 #sequence_length\n",
    "rnn_size = 25  # rnn cell의 갯수\n",
    "PH = 30  # PH\n",
    "\n",
    "\n",
    "# # numpy array인 ndarray에는 append 함수가 없어서 vstack이나 concatenate함수를 이용해서 정의\n",
    "# def npAppend(x, y):\n",
    "#     x = np.vstack((x, y))\n",
    "#     return x\n",
    "\n",
    "# readData reads data from the specified pre-processed input data file.\n",
    "# The function returns an array of input data points and an array of the\n",
    "# corresponding desired outputs.\n",
    "def readData(filePath):\n",
    "    allList = []\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    newPointx = []\n",
    "    newPointy = []\n",
    "    with open(filePath, 'r') as f:\n",
    "        for line in f:\n",
    "            allList.append(float(line))\n",
    "\n",
    "    df = pd.Series(allList)  # 일차원 리스트를 pandas 데이터프레임화\n",
    "    while True:\n",
    "        for i in df[0:7]:\n",
    "            newPointx.append([float(i)])  # 데이터프레임 앞의 7개를 newPointx 리스트에 삽입\n",
    "        newPointy.append(float(df[6 + (PH / 5)]))  # 데이터프레임 그 다음(10번째)을 newPointy 리스트에 삽입\n",
    "        x_data.append(newPointx)  # x_data 리스트에 newPointx 리스트를 삽입 (x_data는 array of array가 됨)\n",
    "        y_data.append(newPointy)  # 위와 동일\n",
    "\n",
    "        newPointx = []  # 다음 반복을 위해 newPointx,y를 빈 리스트로 초기화\n",
    "        newPointy = []\n",
    "        df = df.shift(-1)  # 데이터프레임 왼 쪽으로 1칸 쉬프트\n",
    "        if (math.isnan(df[6 + (PH / 5)])):  # 만약 8번째 데이터프레임이 NaN(Not a Number) 라면 반복 중지\n",
    "            break\n",
    "    x_data = np.asarray(x_data)\n",
    "    y_data = np.asarray(y_data)\n",
    "    data = [x_data, y_data]\n",
    "\n",
    "    return data;\n",
    "\n",
    "#실제 데이터 사용 중지\n",
    "print(\"start\")\n",
    "\n",
    "trainFileName = [85655,209019,365303,485709,553778,573060,579883,822250,839654,885633,895646,920087]\n",
    "testFileName = [1007000,1185429,1393413,3008387]\n",
    "\n",
    "gitTrainFileName = []\n",
    "gitTestFileName = []\n",
    "\n",
    "schTrainFileName=[]\n",
    "schTestFileName=[]\n",
    "\n",
    "trainData_in_list=[]\n",
    "trainData_out_list=[]\n",
    "\n",
    "testData_in_list=[]\n",
    "testData_out_list=[]\n",
    "\n",
    "'''\n",
    "#git_input_data 폴더 밑에 12_test.csv, 12_train.csv 처럼 파일 있으니, 이 이름들을 배열에 저장시켜야 나중에 편해짐\n",
    "gitFileList = os.listdir(\"jchr\")\n",
    "for fn in gitFileList:\n",
    "    if fn.find(\"test\") != -1: #파일이름에 test가 들어간다면\n",
    "        gitTestFileName.append(fn)\n",
    "    elif fn.find(\"train\") != -1: #파일 이름에 train이 들어간다면\n",
    "        gitTrainFileName.append(fn)\n",
    "        \n",
    "'''\n",
    "schFileList = os.listdir(\"sch\")\n",
    "for fn in schFileList:\n",
    "    if fn.find(\"test\") != -1:\n",
    "        schTestFileName.append(fn)\n",
    "    elif fn.find(\"train\") != -1:\n",
    "        schTrainFileName.append(fn)\n",
    "\n",
    "\n",
    "#학습용 데이터 전체 읽기 (실제 데이터)\n",
    "for fn in schTrainFileName:\n",
    "    inData, outData = readData(\"sch/\"+str(fn))\n",
    "    trainData_in_list.append(inData)\n",
    "    trainData_out_list.append(outData)\n",
    "\n",
    "print(\"trainData_in_list_len: \"+str(len(trainData_in_list)))\n",
    "print(\"trainData_out_list_len: \"+str(len(trainData_out_list)))\n",
    "\n",
    "\n",
    "#시험용 데이터 전체 읽기 (실제 데이터)\n",
    "for fn in schTestFileName:\n",
    "    inData, outData = readData(\"sch/\"+str(fn))\n",
    "    testData_in_list.append(inData)\n",
    "    testData_out_list.append(outData)\n",
    "\n",
    "\n",
    "print(\"testData_in_list_len: \"+str(len(testData_in_list)))\n",
    "print(\"testData_out_list_len: \"+str(len(testData_in_list)))\n",
    "'''\n",
    "#학습용 데이터 전체 읽기 (git 데이터)\n",
    "for fn in gitTrainFileName:\n",
    "    inData, outData = readData(\"jchr/\"+str(fn))\n",
    "    trainData_in_list.append(inData)\n",
    "    trainData_out_list.append(outData)\n",
    "\n",
    "print(\"trainData_in_list_len: \"+str(len(trainData_in_list)))\n",
    "print(\"trainData_out_list_len: \"+str(len(trainData_out_list)))\n",
    "\n",
    "#시험용 데이터 전체 읽기 (git 데이터)\n",
    "for fn in gitTestFileName:\n",
    "    inData, outData = readData(\"jchr/\"+str(fn))\n",
    "    testData_in_list.append(inData)\n",
    "    testData_out_list.append(outData)\n",
    "\n",
    "print(\"testData_in_list_len: \"+str(len(testData_in_list)))\n",
    "print(\"testData_out_list_len: \"+str(len(testData_in_list)))\n",
    "'''\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 7, 1], name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\")\n",
    "\n",
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_size, state_is_tuple=True, activation=tf.tanh)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=None)\n",
    "# We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.initialize_all_variables().run()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Training step\n",
    "\n",
    "lossList = []\n",
    "for loop in range(len(trainData_in_list)):\n",
    "    losss = []\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        _, step_loss = sess.run([train, loss],\n",
    "                                feed_dict={X: trainData_in_list[loop], Y: trainData_out_list[loop]})\n",
    "        losss.append(step_loss)\n",
    "    print(str(loop / len(trainData_in_list) * 100) + \"%\")\n",
    "    lossList.append(losss)\n",
    "print(\"DONE\")\n",
    "\n",
    "e=[] #(실제값-예측값)^2 이 담길 리스트\n",
    "rmseList=[] # 테스트케이스별 RMSE 값들이 담길 리스트\n",
    "predictedList=[]\n",
    "desiredList=[]\n",
    "for j in range(len(testData_in_list)):\n",
    "    predictedHyper = 0\n",
    "    predictedHypo = 0\n",
    "\n",
    "    desiredHyper = 0\n",
    "    desiredHypo = 0\n",
    "    \n",
    "    falseLow = 0\n",
    "    falseHigh = 0\n",
    "    predictedHyperList=[]\n",
    "    predictedHypoList=[]\n",
    "    \n",
    "    desiredHyperList=[]\n",
    "    desiredHypoList=[]\n",
    "    \n",
    "    falseLowList=[]\n",
    "    falseHighList=[]\n",
    "    \n",
    "    for i, inputPoint in enumerate(testData_in_list[j]) :\n",
    "        predicted = sess.run(Y_pred, feed_dict={X: [inputPoint]})\n",
    "        predictedList.append(predicted[0][0])\n",
    "        desired = testData_out_list[j][i][0]\n",
    "        desiredList.append(desired)\n",
    "        \n",
    "        e.append( math.pow((predicted[0][0]-desired), 2) )\n",
    "      \n",
    "        #실제로 고혈당\n",
    "        if(desired > 180):\n",
    "            desiredHyper += 1\n",
    "            #실제로 고혈당이면서 예측도 성공한 경우\n",
    "            if(predicted[0][0] > 180):\n",
    "                predictedHyper+=1\n",
    "            elif(abs(desired - predicted[0][0]) > 8):\n",
    "                falseHigh+=1\n",
    "            \n",
    "        if(desired<70):\n",
    "            desiredHypo +=1\n",
    "            #실제로 저혈당이면서 예측도 성공한 경우\n",
    "            if(predicted[0][0]<70):\n",
    "                predictedHypo+=1\n",
    "            elif(abs(desired - predicted[0][0]) > 8):\n",
    "                falseLow+=1\n",
    "    \n",
    "    predictedHyperList.append(predictedHyper)\n",
    "    predictedHypoList.append(predictedHypo)\n",
    "    \n",
    "    desiredHyperList.append(desiredHyper)\n",
    "    desiredHypoList.append(desiredHypo)\n",
    "    \n",
    "    falseLowList.append(falseLow)\n",
    "    falseHighList.append(falseHigh)\n",
    "    \n",
    "\n",
    "    predictedHyper = 0\n",
    "    predictedHypo = 0\n",
    "\n",
    "    desiredHyper = 0\n",
    "    desiredHypo = 0\n",
    "    \n",
    "    falseLow = 0\n",
    "    falseHigh = 0\n",
    "    \n",
    "    avg = sum(e) / len(e)\n",
    "    rmse = math.sqrt(avg)\n",
    "    rmseList.append(rmse)\n",
    "    \n",
    "    #여기에 파일 저장 코드\n",
    "    '''try:\n",
    "        fileName = schTestFileName[j]#이게 예외다 = sch는 다읽은거고 그 다음 jchr읽어야함\n",
    "    except:\n",
    "        fileName = gitTestFileName[j-len(schTestFileName)]'''\n",
    "\n",
    "    fileName = schTestFileName[j]\n",
    "    \n",
    "    #실제-예측 데이터를 텍스트 파일로 저장 (나중에 엑셀같은걸로 차트만들때 편하라고)\n",
    "    realFp = open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-real.txt\", \"w\")\n",
    "    predictFp = open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-predict.txt\", \"w\")\n",
    "\n",
    "    #고/저혈당 실제-예측 횟수 데이터 텍스트 파일로 저장\n",
    "    predictedHyperFp = open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-predictedHyperList.txt\", \"w\")\n",
    "    desiredHyperFp = open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-desiredHyperList.txt\", \"w\")\n",
    "    \n",
    "    predictedHypoFp = open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-predictedHypoList.txt\", \"w\")\n",
    "    desiredHypoFp = open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-desiredHypoList.txt\", \"w\")\n",
    "\n",
    "    falseHighFp = open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-falseHigh.txt\", \"w\")\n",
    "    falseLowFp =open(\"chartData/LSTM/PH\"+str(PH)+\"/\"+fileName+\"-falseLow.txt\", \"w\")\n",
    "\n",
    "    #실제 혈당 저장\n",
    "    for data in desiredList:\n",
    "        realFp.write(str(data)+'\\n')\n",
    "\n",
    "    #예측 혈당 저장\n",
    "    for data in predictedList:\n",
    "        predictFp.write(str(data)+'\\n')\n",
    "\n",
    "    #고혈당 예측한 횟수 저장\n",
    "    for data in predictedHyperList:\n",
    "        predictedHyperFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #고혈당 실제 횟수 저장\n",
    "    for data in desiredHyperList:\n",
    "        desiredHyperFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #저혈당 예측한 횟수 저장\n",
    "    for data in predictedHypoList:\n",
    "        predictedHypoFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #저혈당 실제 횟수 저장\n",
    "    for data in desiredHypoList:\n",
    "        desiredHypoFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #잘못된 고혈당 예측 횟수 저장\n",
    "    for data in falseHighList:\n",
    "        falseHighFp.write(str(data)+\"\\n\")\n",
    "        \n",
    "    #잘못된 저혈당 예측 횟수 저장\n",
    "    for data in falseLowList:\n",
    "        falseLowFp.write(str(data)+\"\\n\")\n",
    "        \n",
    "    realFp.close()\n",
    "    predictFp.close()\n",
    "    predictedHyperFp.close()\n",
    "    desiredHyperFp.close()\n",
    "    predictedHypoFp.close()\n",
    "    desiredHypoFp.close()\n",
    "    falseHighFp.close()\n",
    "    falseLowFp.close()\n",
    "  \n",
    "    predictedList=[]\n",
    "    desiredList=[]\n",
    "    e=[]\n",
    "\n",
    "for i in schTestFileName:\n",
    "    print(i)\n",
    "for i in gitTestFileName:\n",
    "    print(i)\n",
    "\n",
    "print(\"RMSE\")\n",
    "for i in rmseList:\n",
    "    print(str(i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
