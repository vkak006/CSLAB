{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "NUM_EPOCHS = 500  # 반복 횟수\n",
    "chunk_size = 1  # 한 개 요소의 크기\n",
    "# n_chunks = 7 #sequence_length\n",
    "rnn_size = 25  # rnn cell의 갯수\n",
    "PH = 5  # PH\n",
    "\n",
    "\n",
    "# # numpy array인 ndarray에는 append 함수가 없어서 vstack이나 concatenate함수를 이용해서 정의\n",
    "# def npAppend(x, y):\n",
    "#     x = np.vstack((x, y))\n",
    "#     return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# readData reads data from the specified pre-processed input data file.\n",
    "# The function returns an array of input data points and an array of the\n",
    "# corresponding desired outputs.\n",
    "def readData(filePath):\n",
    "    allList = []\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    newPointx = []\n",
    "    newPointy = []\n",
    "    with open(filePath, 'r') as f:\n",
    "        for line in f:\n",
    "            allList.append(float(line))\n",
    "\n",
    "    df = pd.Series(allList)  # 일차원 리스트를 pandas 데이터프레임화\n",
    "    while True:\n",
    "        for i in df[0:7]:\n",
    "            newPointx.append([float(i)])  # 데이터프레임 앞의 7개를 newPointx 리스트에 삽입\n",
    "        newPointy.append(float(df[6 + (PH / 5)]))  # 데이터프레임 그 다음(10번째)을 newPointy 리스트에 삽입\n",
    "        x_data.append(newPointx)  # x_data 리스트에 newPointx 리스트를 삽입 (x_data는 array of array가 됨)\n",
    "        y_data.append(newPointy)  # 위와 동일\n",
    "\n",
    "        newPointx = []  # 다음 반복을 위해 newPointx,y를 빈 리스트로 초기화\n",
    "        newPointy = []\n",
    "        df = df.shift(-1)  # 데이터프레임 왼 쪽으로 1칸 쉬프트\n",
    "        if (math.isnan(df[6 + (PH / 5)])):  # 만약 8번째 데이터프레임이 NaN(Not a Number) 라면 반복 중지\n",
    "            break\n",
    "    x_data = np.asarray(x_data)\n",
    "    y_data = np.asarray(y_data)\n",
    "    data = [x_data, y_data]\n",
    "\n",
    "    return data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 실제 데이터 사용 중지\n",
    "'''\n",
    "trainFileName = [85655,209019,365303,485709,553778,573060,579883,822250,839654,885633,895646,920087]\n",
    "testFileName = [1007000,1185429,1393413,3008387]\n",
    "'''\n",
    "gitTrainFileName = []\n",
    "gitTestFileName = []\n",
    "\n",
    "trainData_in_list = []\n",
    "trainData_out_list = []\n",
    "\n",
    "testData_in_list = []\n",
    "testData_out_list = []\n",
    "\n",
    "trainFileName = []\n",
    "testFileName = []\n",
    "\n",
    "# git_input_data 폴더 밑에 12_test.csv, 12_train.csv 처럼 파일 있으니, 이 이름들을 배열에 저장시켜야 나중에 편해짐\n",
    "gitFileList = os.listdir(\"git_input_data\")\n",
    "for fn in gitFileList:\n",
    "    if fn.find(\"test\") != -1:  # 파일이름에 test가 들어간다면\n",
    "        gitTestFileName.append(fn)\n",
    "    elif fn.find(\"train\") != -1:  # 파일 이름에 train이 들어간다면\n",
    "        gitTrainFileName.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preprocessed-46.csv', 'preprocessed-59.csv', 'preprocessed-45.csv', 'preprocessed-12.csv', 'preprocessed-34.csv', 'preprocessed-16.csv', 'preprocessed-48.csv', 'preprocessed-14.csv', 'preprocessed-50.csv', 'preprocessed-61.csv', 'preprocessed-43.csv', 'preprocessed-29.csv', 'preprocessed-15.csv', 'preprocessed-17.csv']\n",
      "preprocessed-33.csv\n",
      "preprocessed-5.csv\n",
      "preprocessed-26.csv\n",
      "preprocessed-38.csv\n",
      "preprocessed-25.csv\n",
      "preprocessed-70.csv\n",
      "preprocessed-19.csv\n",
      "preprocessed-53.csv\n",
      "preprocessed-36.csv\n",
      "preprocessed-69.csv\n",
      "preprocessed-62.csv\n",
      "preprocessed-42.csv\n",
      "preprocessed-23.csv\n",
      "preprocessed-18.csv\n",
      "preprocessed-4.csv\n",
      "preprocessed-1.csv\n",
      "preprocessed-27.csv\n",
      "preprocessed-31.csv\n",
      "preprocessed-37.csv\n",
      "preprocessed-58.csv\n",
      "preprocessed-39.csv\n",
      "preprocessed-65.csv\n",
      "preprocessed-49.csv\n",
      "preprocessed-57.csv\n",
      "preprocessed-22.csv\n",
      "preprocessed-10.csv\n",
      "preprocessed-32.csv\n",
      "preprocessed-52.csv\n",
      "preprocessed-64.csv\n",
      "preprocessed-35.csv\n",
      "preprocessed-8.csv\n",
      "preprocessed-51.csv\n",
      "preprocessed-24.csv\n",
      "preprocessed-7.csv\n",
      "preprocessed-44.csv\n",
      "preprocessed-55.csv\n",
      "preprocessed-13.csv\n",
      "preprocessed-67.csv\n",
      "preprocessed-47.csv\n",
      "preprocessed-11.csv\n",
      "preprocessed-2.csv\n",
      "preprocessed-3.csv\n",
      "preprocessed-40.csv\n",
      "preprocessed-54.csv\n",
      "preprocessed-68.csv\n",
      "preprocessed-9.csv\n",
      "preprocessed-63.csv\n",
      "preprocessed-20.csv\n",
      "preprocessed-30.csv\n",
      "preprocessed-60.csv\n",
      "preprocessed-21.csv\n",
      "preprocessed-66.csv\n",
      "preprocessed-41.csv\n",
      "preprocessed-6.csv\n",
      "preprocessed-28.csv\n",
      "preprocessed-56.csv\n",
      "trainData_in_list_len: 56\n",
      "trainData_out_list_len: 56\n",
      "preprocessed-46.csv\n",
      "preprocessed-59.csv\n",
      "preprocessed-45.csv\n",
      "preprocessed-12.csv\n",
      "preprocessed-34.csv\n",
      "preprocessed-16.csv\n",
      "preprocessed-48.csv\n",
      "preprocessed-14.csv\n",
      "preprocessed-50.csv\n",
      "preprocessed-61.csv\n",
      "preprocessed-43.csv\n",
      "preprocessed-29.csv\n",
      "preprocessed-15.csv\n",
      "preprocessed-17.csv\n",
      "File I/O elapsed time: 315.7882044315338\n"
     ]
    }
   ],
   "source": [
    "#uci-preprocessed 폴더 밑에 preprocessed-23.csv 처럼 파일 있으니, 이 이름들을 배열에 저장\n",
    "#1번~56번은 학습용, 57번~70번은 시험용에 분리\n",
    "uciFileList = os.listdir(\"uci-preprocessed\")\n",
    "count=1\n",
    "for fn in uciFileList:\n",
    "    if(count>=1 and count<=56):\n",
    "        trainFileName.append(fn)\n",
    "    else:\n",
    "        testFileName.append(fn)\n",
    "    count+=1\n",
    "\n",
    "print(testFileName)\n",
    "\n",
    "#학습용 데이터 전체 읽기 (git 데이터)\n",
    "for fn in trainFileName:\n",
    "    print(str(fn))\n",
    "    try:\n",
    "        inData, outData = readData(\"git_input_data/\"+str(fn))\n",
    "    except:\n",
    "        #위에서 예외가 발생한다는건, 이 파일이 git_input_data가 아닌 uci-preprocessed에 있다는 뜻임\n",
    "        inData, outData = readData(\"uci-preprocessed/\"+str(fn))\n",
    "    trainData_in_list.append(inData)\n",
    "    trainData_out_list.append(outData)\n",
    "\n",
    "print(\"trainData_in_list_len: \"+str(len(trainData_in_list)))\n",
    "print(\"trainData_out_list_len: \"+str(len(trainData_out_list)))\n",
    "\n",
    "#시험용 데이터 전체 읽기 (git 데이터)\n",
    "for fn in testFileName:\n",
    "    print(str(fn))\n",
    "    try:\n",
    "        inData, outData = readData(\"git_input_data/\"+str(fn))\n",
    "    except:\n",
    "        #위에서 예외가 발생한다는건, 이 파일이 git_input_data가 아닌 uci-preprocessed에 있다는 뜻임\n",
    "        inData, outData = readData(\"uci-preprocessed/\"+str(fn))\n",
    "    testData_in_list.append(inData)\n",
    "    testData_out_list.append(outData)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"File I/O elapsed time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preprocessed-33.csv', 'preprocessed-5.csv', 'preprocessed-26.csv', 'preprocessed-38.csv', 'preprocessed-25.csv', 'preprocessed-70.csv', 'preprocessed-19.csv', 'preprocessed-53.csv', 'preprocessed-36.csv', 'preprocessed-69.csv', 'preprocessed-62.csv', 'preprocessed-42.csv', 'preprocessed-23.csv', 'preprocessed-18.csv', 'preprocessed-4.csv', 'preprocessed-1.csv', 'preprocessed-27.csv', 'preprocessed-31.csv', 'preprocessed-37.csv', 'preprocessed-58.csv', 'preprocessed-39.csv', 'preprocessed-65.csv', 'preprocessed-49.csv', 'preprocessed-57.csv', 'preprocessed-22.csv', 'preprocessed-10.csv', 'preprocessed-32.csv', 'preprocessed-52.csv', 'preprocessed-64.csv', 'preprocessed-35.csv', 'preprocessed-8.csv', 'preprocessed-51.csv', 'preprocessed-24.csv', 'preprocessed-7.csv', 'preprocessed-44.csv', 'preprocessed-55.csv', 'preprocessed-13.csv', 'preprocessed-67.csv', 'preprocessed-47.csv', 'preprocessed-11.csv', 'preprocessed-2.csv', 'preprocessed-3.csv', 'preprocessed-40.csv', 'preprocessed-54.csv', 'preprocessed-68.csv', 'preprocessed-9.csv', 'preprocessed-63.csv', 'preprocessed-20.csv', 'preprocessed-30.csv', 'preprocessed-60.csv', 'preprocessed-21.csv', 'preprocessed-66.csv', 'preprocessed-41.csv', 'preprocessed-6.csv', 'preprocessed-28.csv', 'preprocessed-56.csv', 'preprocessed-46.csv', 'preprocessed-59.csv', 'preprocessed-45.csv', 'preprocessed-12.csv', 'preprocessed-34.csv', 'preprocessed-16.csv', 'preprocessed-48.csv', 'preprocessed-14.csv', 'preprocessed-50.csv', 'preprocessed-61.csv', 'preprocessed-43.csv', 'preprocessed-29.csv', 'preprocessed-15.csv', 'preprocessed-17.csv']\n"
     ]
    }
   ],
   "source": [
    "print(uciFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hadoop/anaconda3/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 7, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "\n",
    "#layer = {'weights':tf.Variable(tf.random_normal([rnn_size, 1])),'biases':tf.Variable(tf.random_normal([1]))}\n",
    "\n",
    "\n",
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_size, state_is_tuple=True, activation=tf.nn.relu)\n",
    "#cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_size, state_is_tuple=True, activation=tf.tanh)\n",
    "\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=None)\n",
    "# We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "#loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "loss = tf.reduce_mean(tf.square(Y_pred - Y))\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.initialize_all_variables().run()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "1.7857142857142856%\n",
      "3.571428571428571%\n",
      "5.357142857142857%\n",
      "7.142857142857142%\n",
      "8.928571428571429%\n",
      "10.714285714285714%\n",
      "12.5%\n",
      "14.285714285714285%\n",
      "16.071428571428573%\n",
      "17.857142857142858%\n",
      "19.642857142857142%\n",
      "21.428571428571427%\n",
      "23.214285714285715%\n",
      "25.0%\n",
      "26.785714285714285%\n",
      "28.57142857142857%\n",
      "30.357142857142854%\n",
      "32.142857142857146%\n",
      "33.92857142857143%\n",
      "35.714285714285715%\n",
      "37.5%\n",
      "39.285714285714285%\n",
      "41.07142857142857%\n",
      "42.857142857142854%\n",
      "44.642857142857146%\n",
      "46.42857142857143%\n",
      "48.214285714285715%\n",
      "50.0%\n",
      "51.78571428571429%\n",
      "53.57142857142857%\n",
      "55.35714285714286%\n",
      "57.14285714285714%\n",
      "58.92857142857143%\n",
      "60.71428571428571%\n",
      "62.5%\n",
      "64.28571428571429%\n",
      "66.07142857142857%\n",
      "67.85714285714286%\n",
      "69.64285714285714%\n",
      "71.42857142857143%\n",
      "73.21428571428571%\n",
      "75.0%\n",
      "76.78571428571429%\n",
      "78.57142857142857%\n",
      "80.35714285714286%\n",
      "82.14285714285714%\n",
      "83.92857142857143%\n",
      "85.71428571428571%\n",
      "87.5%\n",
      "89.28571428571429%\n",
      "91.07142857142857%\n",
      "92.85714285714286%\n",
      "94.64285714285714%\n",
      "96.42857142857143%\n",
      "98.21428571428571%\n",
      "DONE\n",
      "ML elapsed time: 449.0047380924225\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Training step\n",
    "\n",
    "lossList = []\n",
    "for loop in range(len(trainData_in_list)):\n",
    "    losss = []\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        _, step_loss = sess.run([train, loss],\n",
    "                                feed_dict={X: trainData_in_list[loop], Y: trainData_out_list[loop]})\n",
    "        losss.append(step_loss)\n",
    "    print(str(loop / len(trainFileName) * 100) + \"%\")\n",
    "    lossList.append(losss)\n",
    "print(\"DONE\")\n",
    "end_time = time.time()\n",
    "print(\"ML elapsed time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aaeb08994438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputPoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData_in_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputPoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mpredictedList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdesired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestData_out_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "e=[] #(실제값-예측값)^2 이 담길 리스트\n",
    "rmseList=[] # 테스트케이스별 RMSE 값들이 담길 리스트\n",
    "for j in range(len(testData_in_list)):\n",
    "    for i, inputPoint in enumerate(testData_in_list[j]) :\n",
    "        \n",
    "        predicted = sess.run(prediction, feed_dict={x: [inputPoint]})\n",
    "        predictedList.append(predicted[0][0])\n",
    "        desired = testData_out_list[j][i][0]\n",
    "        desiredList.append(desired)\n",
    "        \n",
    "        e.append( math.pow((predicted[0][0]-desired), 2) )\n",
    "        \n",
    "        #실제로 고혈당\n",
    "        if(desired > 180):\n",
    "            desiredHyper += 1\n",
    "            #실제로 고혈당이면서 예측도 성공한 경우\n",
    "            if(predicted[0][0] > 180):\n",
    "                predictedHyper+=1\n",
    "            elif(abs(desired - predicted[0][0]) > 8):\n",
    "                falseHigh+=1\n",
    "            \n",
    "        if(desired<70):\n",
    "            desiredHypo +=1\n",
    "            #실제로 저혈당이면서 예측도 성공한 경우\n",
    "            if(predicted[0][0]<70):\n",
    "                predictedHypo+=1\n",
    "            elif(abs(desired - predicted[0][0]) > 8):\n",
    "                falseLow+=1\n",
    "        \n",
    "    print(\"desiredHyper: \"+str(desiredHyper)+\", predictedHyper: \"+\n",
    "          str(predictedHyper)+\", desiredHypo: \"+str(desiredHypo)+\", predictedHypo: \"+str(predictedHypo)+\n",
    "         \", falseHigh: \"+str(falseHigh)+\", falseLow: \"+str(falseLow))\n",
    "    \n",
    "    predictedHyperList.append(predictedHyper)\n",
    "    predictedHypoList.append(predictedHypo)\n",
    "    \n",
    "    desiredHyperList.append(desiredHyper)\n",
    "    desiredHypoList.append(desiredHypo)\n",
    "    \n",
    "    falseLowList.append(falseLow)\n",
    "    falseHighList.append(falseHigh)\n",
    "    \n",
    "    \n",
    "    predictedHyper = 0\n",
    "    predictedHypo = 0\n",
    "\n",
    "    desiredHyper = 0\n",
    "    desiredHypo = 0\n",
    "    \n",
    "    falseLow = 0\n",
    "    falseHigh = 0\n",
    "    \n",
    "    avg = sum(e) / len(e)\n",
    "    rmse = math.sqrt(avg)\n",
    "    rmseList.append(rmse)\n",
    "    \n",
    "    \n",
    "    print(\"Patient: \"+str(testFileName[j])+\", RMSE: \"+str(rmse))\n",
    "    #실제-예측 데이터를 텍스트 파일로 저장 (나중에 엑셀같은걸로 차트만들때 편하라고)\n",
    "    realFp = open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-real.txt\", \"w\")\n",
    "    predictFp = open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-predict.txt\", \"w\")\n",
    "\n",
    "    #고/저혈당 실제-예측 횟수 데이터 텍스트 파일로 저장\n",
    "    predictedHyperFp = open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-predictedHyperList.txt\", \"w\")\n",
    "    desiredHyperFp = open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-desiredHyperList.txt\", \"w\")\n",
    "    \n",
    "    predictedHypoFp = open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-predictedHypoList.txt\", \"w\")\n",
    "    desiredHypoFp = open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-desiredHypoList.txt\", \"w\")\n",
    "\n",
    "    falseHighFp = open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-falseHigh.txt\", \"w\")\n",
    "    falseLowFp =open(\"chartData/git+uci/RNN/PH\"+str(PH)+\"/\"+testFileName[j]+\"-falseLow.txt\", \"w\")\n",
    "\n",
    "    #실제 혈당 저장\n",
    "    for data in desiredList:\n",
    "        realFp.write(str(data)+'\\n')\n",
    "\n",
    "    #예측 혈당 저장\n",
    "    for data in predictedList:\n",
    "        predictFp.write(str(data)+'\\n')\n",
    "\n",
    "    #고혈당 예측한 횟수 저장\n",
    "    for data in predictedHyperList:\n",
    "        predictedHyperFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #고혈당 실제 횟수 저장\n",
    "    for data in desiredHyperList:\n",
    "        desiredHyperFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #저혈당 예측한 횟수 저장\n",
    "    for data in predictedHypoList:\n",
    "        predictedHypoFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #저혈당 실제 횟수 저장\n",
    "    for data in desiredHypoList:\n",
    "        desiredHypoFp.write(str(data)+\"\\n\")\n",
    "\n",
    "    #잘못된 고혈당 예측 횟수 저장\n",
    "    for data in falseHighList:\n",
    "        falseHighFp.write(str(data)+\"\\n\")\n",
    "        \n",
    "    #잘못된 저혈당 예측 횟수 저장\n",
    "    for data in falseLowList:\n",
    "        falseLowFp.write(str(data)+\"\\n\")\n",
    "        \n",
    "    realFp.close()\n",
    "    predictFp.close()\n",
    "    predictedHyperFp.close()\n",
    "    desiredHyperFp.close()\n",
    "    predictedHypoFp.close()\n",
    "    desiredHypoFp.close()\n",
    "    falseHighFp.close()\n",
    "    falseLowFp.close()\n",
    "    \n",
    "    predictedList=[]\n",
    "    desiredList=[]\n",
    "    e=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
