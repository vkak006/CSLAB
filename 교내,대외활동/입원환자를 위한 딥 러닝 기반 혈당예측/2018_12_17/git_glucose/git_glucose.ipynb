{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:85655_train.csv, x_data len: 680, y_data len: 680\n",
      "path:85655_test.csv, x_data len: 165, y_data len: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 174 data:\n",
      "98.0\n",
      "98.0\n",
      "98.0\n",
      "98.0\n",
      "98.0\n",
      "98.0\n",
      "97.0\n",
      "97.0\n",
      "97.0\n",
      "96.0\n",
      "97.0\n",
      "97.0\n",
      "97.0\n",
      "96.0\n",
      "97.0\n",
      "98.0\n",
      "98.0\n",
      "98.0\n",
      "99.0\n",
      "99.0\n",
      "99.0\n",
      "100.0\n",
      "101.0\n",
      "102.0\n",
      "101.0\n",
      "101.0\n",
      "101.0\n",
      "101.0\n",
      "101.0\n",
      "102.0\n",
      "102.0\n",
      "103.0\n",
      "104.0\n",
      "103.0\n",
      "103.0\n",
      "102.0\n",
      "102.0\n",
      "102.0\n",
      "102.0\n",
      "103.0\n",
      "103.0\n",
      "103.0\n",
      "103.0\n",
      "102.0\n",
      "102.0\n",
      "101.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "99.0\n",
      "97.0\n",
      "99.0\n",
      "101.0\n",
      "103.0\n",
      "103.0\n",
      "102.0\n",
      "101.0\n",
      "99.0\n",
      "99.0\n",
      "98.0\n",
      "98.0\n",
      "100.0\n",
      "101.0\n",
      "102.0\n",
      "100.0\n",
      "100.0\n",
      "101.0\n",
      "96.0\n",
      "100.0\n",
      "103.0\n",
      "111.0\n",
      "115.0\n",
      "113.0\n",
      "112.0\n",
      "113.0\n",
      "115.0\n",
      "119.0\n",
      "115.0\n",
      "113.0\n",
      "110.0\n",
      "110.0\n",
      "110.0\n",
      "110.0\n",
      "109.0\n",
      "109.0\n",
      "109.0\n",
      "106.0\n",
      "107.0\n",
      "110.0\n",
      "114.0\n",
      "124.0\n",
      "123.0\n",
      "121.0\n",
      "120.0\n",
      "116.0\n",
      "112.0\n",
      "110.0\n",
      "108.0\n",
      "104.0\n",
      "104.0\n",
      "105.0\n",
      "107.0\n",
      "110.0\n",
      "111.0\n",
      "111.0\n",
      "112.0\n",
      "113.0\n",
      "119.0\n",
      "121.0\n",
      "120.0\n",
      "121.0\n",
      "122.0\n",
      "120.0\n",
      "120.0\n",
      "119.0\n",
      "114.0\n",
      "122.0\n",
      "123.0\n",
      "116.0\n",
      "115.0\n",
      "116.0\n",
      "118.0\n",
      "125.0\n",
      "132.0\n",
      "118.0\n",
      "105.0\n",
      "116.0\n",
      "131.0\n",
      "130.0\n",
      "129.0\n",
      "131.0\n",
      "131.0\n",
      "129.0\n",
      "134.0\n",
      "129.0\n",
      "136.0\n",
      "139.0\n",
      "147.0\n",
      "152.0\n",
      "148.0\n",
      "151.0\n",
      "153.0\n",
      "157.0\n",
      "155.0\n",
      "154.0\n",
      "156.0\n",
      "155.0\n",
      "149.0\n",
      "151.0\n",
      "146.0\n",
      "139.0\n",
      "143.0\n",
      "150.0\n",
      "146.0\n",
      "150.0\n",
      "156.0\n",
      "151.0\n",
      "148.0\n",
      "155.0\n",
      "160.0\n",
      "160.0\n",
      "155.0\n",
      "154.0\n",
      "154.0\n",
      "155.0\n",
      "Number of test points:  165\n",
      "Number of lows:  29\n",
      "Number of highs:  18\n",
      "Number of 'normal' points:  118\n",
      "\n",
      "MSE:  15.225\n",
      "\n",
      "Low prediction accuracy:  89.65517241379311 %\n",
      "Number of false lows:  0\n",
      "\n",
      "High prediction accuracy:  83.33333333333333 %\n",
      "Number of false highs:  0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# CISC 452\n",
    "# Prediction of Blood Glusose Levels based on RTCGM Data\n",
    "#\n",
    "# November 10, 2016\n",
    "#\n",
    "# This script implements a multi-layer feed-forward neural network for glucose\n",
    "# prediciton\n",
    "#\n",
    "# The network has 7 input nodes and 1 output node. If the current time is 'T',\n",
    "# then the inputs and output represent the blood glucose measurements at the\n",
    "# following times:\n",
    "#   Inputs:     - T\n",
    "#               - (T - 10 mins)\n",
    "#               - (T - 20 mins)\n",
    "#               - (T - 30 mins)\n",
    "#               - (T - 40 mins)\n",
    "#               - (T - 50 mins)\n",
    "#               - (T - 60 mins)\n",
    "#\n",
    "#   Output:     - (T + 20 mins)\n",
    "#\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 1500 # Number of training epochs\n",
    "\n",
    "# readData reads data from the specified pre-processed input data file.\n",
    "# The function returns an array of input data points and an array of the\n",
    "# corresponding desired outputs.\n",
    "def readData(filePath) :\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    allList = []\n",
    "    newPointx=[]\n",
    "    newPointy=[]\n",
    "    \n",
    "    with open(filePath, 'r') as f:\n",
    "        for line in f:\n",
    "            allList.append(float(line))\n",
    "\n",
    "    df = pd.Series(allList) #일차원 리스트를 pandas 데이터프레임화\n",
    "\n",
    "    while True:\n",
    "        for i in df[0:7]: \n",
    "            newPointx.append(float(i)) #데이터프레임 앞의 7개를 newPointx 리스트에 삽입\n",
    "        newPointy.append(float(df[7])) #데이터프레임 그 다음(8번째)을 newPointy 리스트에 삽입\n",
    "\n",
    "        x_data.append(newPointx) #x_data 리스트에 newPointx 리스트를 삽입 (x_data는 array of array가 됨)\n",
    "        y_data.append(newPointy) #위와 동일\n",
    "\n",
    "        newPointx=[] #다음 반복을 위해 newPointx,y를 빈 리스트로 초기화\n",
    "        newPointy=[]\n",
    "        df=df.shift(-1) #데이터프레임 왼 쪽으로 1칸 쉬프트\n",
    "        if(math.isnan(df[7])): #만약 8번째 데이터프레임이 NaN(Not a Number) 라면 반복 중지\n",
    "            break\n",
    "\n",
    "    #배열 갯수 보정작업\n",
    "    #데이터의 개수가 항상 8의 배수가 아니기 때문에 x_data의 마지막 원소 리스트가 항상 7개가 아닐수 있고\n",
    "    #y_data의 마지막 원소 리스트가 항상 1개가 아닐 수 있기 때문에 \n",
    "    #빈 칸들은 0으로 채워주기 위한 작업\n",
    "    if(len(x_data[-1]) != 7):\n",
    "       xSize = 7-len(x_data[-1])\n",
    "       for i in range(xSize):\n",
    "           x_data[-1].append(0.0)\n",
    "    if(len(y_data[-1])!=1):\n",
    "       y_data[-1].append(0.0)  \n",
    "    \n",
    "    data = [x_data, y_data]\n",
    "    return data;\n",
    "\n",
    "# evaluateNetwork runs the trained network on the the provided network and\n",
    "# reports the following evaluation metrics:\n",
    "#   - mean squared prediction error\n",
    "#   - percentage of lows that were correctly identified\n",
    "#   - percentage of highs that were corretly identified\n",
    "#   - number of falsely reported lows\n",
    "#   - number of falsely reported highs\n",
    "#\n",
    "# These metrics are defined as follows:\n",
    "#   - MSE:\n",
    "#       -> Average of (y_desired - y_actual)^2 for each test point\n",
    "#   - Low prediction accuracy:\n",
    "#       -> 100 * (Number of correct lows) / (Number of lows)\n",
    "#       -> Lows are any blood glucose level less than 70 mg/dL\n",
    "#   - High prediction accuracy:\n",
    "#       -> 100 * (Number of correct highs) / (Number of highs)\n",
    "#       -> Highs are any blood glucose level greater than 200\n",
    "#   - Number of false lows:\n",
    "#       -> Number of false lows where (y_desired - y_actual) > 6\n",
    "#       -> Note: false alarms are not counted if the prediction error is small\n",
    "#   - Number of false highs:\n",
    "#       -> Number of false highs where (y_actual - y_desired) > 6\n",
    "#       -> Note: false alarms are not counted if the prediciton error is small\n",
    "def evaluateNetwork(session, inData, outData, prediction) :\n",
    "    \n",
    "    # Compute mse:\n",
    "    mse = session.run(tf.reduce_mean(tf.square(prediction - y_desired)), feed_dict={x: inData, y_desired: outData})\n",
    "    numTestPoints = len(inData)\n",
    "    numPredictedLows = 0\n",
    "    numLows = 0\n",
    "    numFalseLows = 0\n",
    "    numPredictedHighs = 0\n",
    "    numHighs = 0\n",
    "    numFalseHighs = 0\n",
    "    for i, inputPoint in enumerate(inData) :\n",
    "        # Apply network on current point:\n",
    "        predicted = session.run(prediction, feed_dict={x: [inputPoint]})\n",
    "        desired = outData[i][0]\n",
    "        \n",
    "        #print(predicted[0][0])\n",
    "        print(desired)\n",
    "        \n",
    "        # Update numLows, numHighs:\n",
    "        if(desired < 100) :\n",
    "            numLows += 1\n",
    "        elif(desired > 150) :\n",
    "            numHighs += 1\n",
    "\n",
    "        # Update prediction counts:\n",
    "        if(predicted < 100) : # If predicted low\n",
    "            if(desired < 100) : # If low prediction was correct\n",
    "                numPredictedLows += 1\n",
    "            elif((desired - predicted) > 8) : # If low prediction was incorrect and error was 'large'\n",
    "                numFalseLows += 1\n",
    "        elif(predicted > 150) : # If predicted high\n",
    "            if(desired > 150) : # If high prediction was correct\n",
    "                numPredictedHighs += 1\n",
    "            elif((predicted - desired) > 8) : # If high prediction was incorrect and error was 'large'\n",
    "                numFalseHighs += 1\n",
    "\n",
    "    # Print results:\n",
    "    print('Number of test points: ', numTestPoints)\n",
    "    print('Number of lows: ', numLows)\n",
    "    print('Number of highs: ', numHighs)\n",
    "    print(\"Number of 'normal' points: \", numTestPoints - numLows - numHighs)\n",
    "    print('') # New line\n",
    "    print('MSE: ', mse)\n",
    "    print('')\n",
    "    print('Low prediction accuracy: ', 100 * numPredictedLows / numLows, '%')\n",
    "    print('Number of false lows: ', numFalseLows)\n",
    "    print('')\n",
    "    print('High prediction accuracy: ', 100 * numPredictedHighs / numHighs, '%')\n",
    "    print('Number of false highs: ', numFalseHighs)\n",
    "    \n",
    "# End evaluateNetwork(...)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 7], name='x') # Input placeholder\n",
    "y_desired = tf.placeholder(tf.float32, [None, 1], name='y_desired') # Desired output placeholder\n",
    "\n",
    "# feedForwardNN describes the model of the feed forward neural network being\n",
    "# used. The selected architecture consists of two hidden layers containing 15\n",
    "# nodes each. All nodes employ a linear activation function.\n",
    "def feedForwardNN(x) :\n",
    "    # Weights from inputs to first hidden layer (15 nodes):\n",
    "    Wh1 = tf.Variable(tf.random_uniform([7, 15], minval = -1, maxval = 1, dtype = tf.float32))\n",
    "    # Bias for first hidden layer:\n",
    "    bh1 = tf.Variable(tf.zeros([1, 15]))\n",
    "\n",
    "    # Weights from first hidden layer to second (15 nodes):\n",
    "    Wh2 = tf.Variable(tf.random_uniform([15, 15], minval = -1, maxval = 1, dtype = tf.float32)) # The weights from each of the 784 inputs to the 10 output nodes\n",
    "    # Bias for second hidden layer:\n",
    "    bh2 = tf.Variable(tf.zeros([1, 15])) # One bias input for each of the 10 output nodes\n",
    "\n",
    "    # Weights from second hidden layer to output layer (1 node):\n",
    "    Wo = tf.Variable(tf.random_uniform([15, 1], minval = -1, maxval = 1, dtype = tf.float32))\n",
    "    # Bias to output node:\n",
    "    bo = tf.Variable(tf.zeros([1, 1]))\n",
    "\n",
    "    # Nodes have no output function (they simply output their activation):\n",
    "    h1 = tf.add(tf.matmul(x, Wh1), bh1) # Hidden layer 1 output\n",
    "    h2 = tf.add(tf.matmul(h1, Wh2), bh2) # Hidden layer 2 output\n",
    "    output = tf.add(tf.matmul(h2, Wo), bo) # Network output\n",
    "\n",
    "    return output\n",
    "\n",
    "def trainFFNN(x):\n",
    "    \n",
    "    \n",
    "    trainData_in, trainData_out = readData('85655_train.csv')\n",
    "    testData_in, testData_out = readData('85655_test.csv')\n",
    "\n",
    "    prediction = feedForwardNN(x)\n",
    "\n",
    "    # Error function to be minimized is the mean square error:\n",
    "    loss = tf.reduce_mean(tf.square(prediction - y_desired))\n",
    "\n",
    "    # Define training algorithm (Adam Optimizer):\n",
    "    # Note: AdamOptimizer produced better results than the GradientDescentOptimizer\n",
    "    #train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "    # Train:\n",
    "    errors = []\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.initialize_all_variables().run()\n",
    "    for i in range(NUM_EPOCHS): # 1000 training epochs\n",
    "        ### Batch training was tested, but per-epoch produced better results:\n",
    "        # Train with one batch at a time:\n",
    "        #for start, end in zip(range(0, len(trainData_in), BATCH_SIZE), range(BATCH_SIZE, len(trainData_in), BATCH_SIZE)):\n",
    "        #    sess.run(train_step, feed_dict={x: trainData_in[start:end], y_desired: trainData_out[start:end]})\n",
    "\n",
    "        # Per-Epoch training:\n",
    "        \n",
    "        #print({x: trainData_in, y_desired: trainData_out})\n",
    "        sess.run(train_step, feed_dict={x: trainData_in, y_desired: trainData_out})\n",
    "        \n",
    "        # Print MSE on test data after every 10 epochs\n",
    "        # i % 10 == 0 :\n",
    "        #    mse = sess.run(tf.reduce_mean(tf.square(prediction - y_desired)), feed_dict={x: testData_in, y_desired: testData_out})\n",
    "        #    errors.append(mse)\n",
    "        #    print(mse)\n",
    "\n",
    "    # Output the desired and actual outputs for each test data point\n",
    "    #for i, inputPoint in enumerate(testData_in) :\n",
    "    #    output = sess.run(y, feed_dict={x: [inputPoint]})\n",
    "    #    print('desired: ', testData_out[i], ', actual: ', output)\n",
    "\n",
    "    # Test:\n",
    "    print('Patient 174 data:')\n",
    "    evaluateNetwork(sess, testData_in, testData_out, prediction)\n",
    "# End trainFFNN(x)\n",
    "\n",
    "trainFFNN(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
