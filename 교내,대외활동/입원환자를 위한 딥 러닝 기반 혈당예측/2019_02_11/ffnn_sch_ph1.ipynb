{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "NUM_EPOCHS = 1500 # Number of training epochs\n",
    "PH = 1\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "def readData(filePath) :\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    allList = []\n",
    "    newPointx=[]\n",
    "    newPointy=[]\n",
    "    \n",
    "    with open(filePath, 'r') as f:\n",
    "        for line in f:\n",
    "            allList.append(float(line))\n",
    "\n",
    "    df = pd.Series(allList) #일차원 리스트를 pandas 데이터프레임화\n",
    "\n",
    "    while True:\n",
    "        for i in df[0:7]: \n",
    "            newPointx.append(float(i)) #데이터프레임 앞의 7개를 newPointx 리스트에 삽입\n",
    "        newPointy.append(float(df[6 + (PH)])) #데이터프레임 그 다음(10번째)을 newPointy 리스트에 삽입\n",
    "\n",
    "        x_data.append(newPointx) #x_data 리스트에 newPointx 리스트를 삽입 (x_data는 array of array가 됨)\n",
    "        y_data.append(newPointy) #위와 동일\n",
    "\n",
    "        newPointx=[] #다음 반복을 위해 newPointx,y를 빈 리스트로 초기화\n",
    "        newPointy=[]\n",
    "        df=df.shift(-1) #데이터프레임 왼 쪽으로 1칸 쉬프트\n",
    "        if(math.isnan(df[6 + (PH)])): #만약 8번째 데이터프레임이 NaN(Not a Number) 라면 반복 중지\n",
    "            break\n",
    "\n",
    "    #배열 갯수 보정작업\n",
    "    #데이터의 개수가 항상 8의 배수가 아니기 때문에 x_data의 마지막 원소 리스트가 항상 7개가 아닐수 있고\n",
    "    #y_data의 마지막 원소 리스트가 항상 1개가 아닐 수 있기 때문에 \n",
    "    #빈 칸들은 0으로 채워주기 위한 작업\n",
    "    if(len(x_data[-1]) != 7):\n",
    "       xSize = 5-len(x_data[-1])\n",
    "       for i in range(xSize):\n",
    "           x_data[-1].append(0.0)\n",
    "    if(len(y_data[-1])!=1):\n",
    "       y_data[-1].append(0.0)  \n",
    "    \n",
    "    data = [x_data, y_data]\n",
    "    return data;\n",
    "\n",
    "filename = os.listdir(\"sch\")\n",
    "\n",
    "train_data_name = []\n",
    "test_data_name = []\n",
    "\n",
    "for fn in filename:\n",
    "    if fn.find(\"test\") != -1:\n",
    "        test_data_name.append(fn)\n",
    "    elif fn.find(\"train\") != -1:\n",
    "        train_data_name.append(fn)\n",
    "\n",
    "\n",
    "total_x_data = []\n",
    "total_y_data = []        \n",
    "        \n",
    "train_x_data = []\n",
    "train_y_data = []\n",
    "for fn in train_data_name:\n",
    "    x,y = readData(\"sch/\"+str(fn))\n",
    "    train_x_data.append(x)\n",
    "    total_x_data.append(x)\n",
    "    train_y_data.append(y)\n",
    "    total_y_data.append(y)\n",
    "    \n",
    "\n",
    "test_x_data = []\n",
    "test_y_data = []\n",
    "for fn in test_data_name:\n",
    "    x,y = readData(\"sch/\"+str(fn))\n",
    "    test_x_data.append(x)\n",
    "    total_x_data.append(x)\n",
    "    test_y_data.append(y)\n",
    "    total_y_data.append(y)\n",
    "\n",
    "#print(total_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(373, 7), b.shape=(7, 15), m=373, n=15, k=7\n\t [[{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_3, Variable/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-3675cbe498c5>\", line 13, in <module>\n    h1 = tf.add(tf.matmul(x,w1),b1)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py\", line 2053, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(373, 7), b.shape=(7, 15), m=373, n=15, k=7\n\t [[{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_3, Variable/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(373, 7), b.shape=(7, 15), m=373, n=15, k=7\n\t [[{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_3, Variable/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3675cbe498c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_x_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_x_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_y_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(373, 7), b.shape=(7, 15), m=373, n=15, k=7\n\t [[{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_3, Variable/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-3675cbe498c5>\", line 13, in <module>\n    h1 = tf.add(tf.matmul(x,w1),b1)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py\", line 2053, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(373, 7), b.shape=(7, 15), m=373, n=15, k=7\n\t [[{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_3, Variable/read)]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,7])\n",
    "y = tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([7,15],minval = -1 , maxval = 1,dtype=tf.float32))\n",
    "b1 = tf.Variable(tf.zeros([1,15]))\n",
    "\n",
    "w2 = tf.Variable(tf.random_uniform([15,15],minval = -1,maxval =1,dtype=tf.float32))\n",
    "b2 = tf.Variable(tf.zeros([1,15]))\n",
    "\n",
    "w3 = tf.Variable(tf.random_uniform([15,1],minval = -1,maxval = 1,dtype=tf.float32))\n",
    "b3 = tf.Variable(tf.zeros([1,1]))\n",
    "\n",
    "h1 = tf.add(tf.matmul(x,w1),b1)\n",
    "h2 = tf.add(tf.matmul(h1,w2),b2)\n",
    "func = tf.add(tf.matmul(h2,w3),b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(func-y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess =tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(len(total_x_data)):\n",
    "    for k in range(1000):\n",
    "        sess.run(train,feed_dict={x:total_x_data[i],y:total_y_data[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = test_x_data[0]\n",
    "pre_data = []\n",
    "\n",
    "input_list = []\n",
    "print(\"혈당 값 7개의 입력 : \")\n",
    "for i in range(7):\n",
    "    k = input()\n",
    "    input_list.append(k)\n",
    "\n",
    "for i,k in enumerate(predict):\n",
    "    pre = sess.run(func,feed_dict={x:[k]})\n",
    "    pre_data.append(pre[0])\n",
    "\n",
    "input_list = np.array(input_list)\n",
    "predict = sess.run(func,feed_dict={x:[input_list]})[0][0]\n",
    "\n",
    "if predict - float(input_list[6])>0:\n",
    "    print(\"혈당이 높아집니다\")\n",
    "elif predict - float(input_list[6])<0:\n",
    "    print(\"혈당이 낮아집니다\")\n",
    "else:\n",
    "    print(\"혈당이 같습니다\")\n",
    "\n",
    "print(\"예측 혈당 : \" + str(predict))\n",
    "    \n",
    "plt.plot(pre_data,color=\"red\")\n",
    "#plt.plot(test_y_data[0],color=\"blue\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
