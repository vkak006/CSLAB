{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365303_train.csv제외\n",
      "885633_train.csv제외\n",
      "365303_test.csv제외\n",
      "885633_test.csv제외\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "\n",
    "PH = 5\n",
    "\n",
    "def readData(filename):\n",
    "    EntryData = []\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    tmp_x = []\n",
    "    tmp_y = []\n",
    "    with open(filename,'r') as f:\n",
    "        for line in f:\n",
    "            EntryData.append(float(line))\n",
    "    \n",
    "    df = pd.Series(EntryData)\n",
    "\n",
    "    while True:\n",
    "        for i in df[0:7]:\n",
    "            tmp_x.append([float(i)])\n",
    "        tmp_y.append(float(df[7 + (PH/5)]))\n",
    "        x_data.append(tmp_x)\n",
    "        y_data.append(tmp_y)\n",
    "        \n",
    "        tmp_x = []\n",
    "        tmp_y = []\n",
    "        df = df.shift(-1)\n",
    "        if(math.isnan(df[7+(PH/5)])):\n",
    "            break\n",
    "        \n",
    "    if(len(x_data[-1]) != 7):\n",
    "       xSize = 7-len(x_data[-1])\n",
    "       for i in range(xSize):\n",
    "           x_data[-1].append(0.0)\n",
    "    if(len(y_data[-1])!=1):\n",
    "       y_data[-1].append(0.0)\n",
    "    \n",
    "    x_data = np.asarray(x_data)\n",
    "    y_data = np.asarray(y_data)\n",
    "    data = [x_data,y_data]\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "filename = os.listdir(\"sch\")\n",
    "\n",
    "train_data_name = []\n",
    "test_data_name = []\n",
    "\n",
    "for fn in filename:\n",
    "    if fn.find(\"test\") != -1:\n",
    "        test_data_name.append(fn)\n",
    "    elif fn.find(\"train\") != -1:\n",
    "        train_data_name.append(fn)\n",
    "\n",
    "#total_x_data = []\n",
    "#total_y_data = []        \n",
    "\n",
    "train_x_data = []\n",
    "train_y_data = []\n",
    "\n",
    "for fn in train_data_name:\n",
    "    if fn.find(\"885633\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    elif fn.find(\"365303\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    else:\n",
    "        x,y = readData(\"sch/\"+str(fn))\n",
    "        train_x_data.append(x)\n",
    "        #total_x_data.append(x)\n",
    "        train_y_data.append(y)\n",
    "        #total_y_data.append(y)\n",
    "\n",
    "\n",
    "test_x_data = []\n",
    "test_y_data = []\n",
    "for fn in test_data_name:\n",
    "    if fn.find(\"885633\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    elif fn.find(\"365303\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    else:\n",
    "        x,y = readData(\"sch/\"+str(fn))\n",
    "        test_x_data.append(x)\n",
    "        #total_x_data.append(x)\n",
    "        test_y_data.append(y)\n",
    "        #total_y_data.append(y)\n",
    "#print(A1cList)\n",
    "#print(total_y_data)\n",
    "#print(train_x_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(15,input_shape=(7,1)))\n",
    "model.add(Dense(1,activation=\"linear\"))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 9 arrays: [array([[[  11.6],\n        [ 178. ],\n        [ 182. ],\n        ..., \n        [ 179. ],\n        [ 178. ],\n        [ 177. ]],\n\n       [[ 178. ],\n        [ 182. ],\n        [ 180. ],\n        ..., \n       ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-93c15402229c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 9 arrays: [array([[[  11.6],\n        [ 178. ],\n        [ 182. ],\n        ..., \n        [ 179. ],\n        [ 178. ],\n        [ 177. ]],\n\n       [[ 178. ],\n        [ 182. ],\n        [ 180. ],\n        ..., \n       ..."
     ]
    }
   ],
   "source": [
    "model.fit(train_x_data,train_y_data,epochs=500,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
