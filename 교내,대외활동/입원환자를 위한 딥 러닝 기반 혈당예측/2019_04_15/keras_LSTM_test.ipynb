{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920087_train.csv\n",
      "822250_train.csv\n",
      "209019_train.csv\n",
      "85655_train.csv\n",
      "553778_train.csv\n",
      "579883_train.csv\n",
      "839654_train.csv\n",
      "1393413_train.csv\n",
      "365303_train.csv제외\n",
      "1185429_train.csv\n",
      "885633_train.csv제외\n",
      "1185429_test.csv\n",
      "839654_test.csv\n",
      "579883_test.csv\n",
      "85655_test.csv\n",
      "209019_test.csv\n",
      "365303_test.csv\n",
      "365303_test.csv제외\n",
      "885633_test.csv\n",
      "885633_test.csv제외\n",
      "822250_test.csv\n",
      "1393413_test.csv\n",
      "553778_test.csv\n",
      "920087_test.csv\n",
      "[[ 10.   11.6]\n",
      " [ 10.   11.6]\n",
      " [ 10.   11.6]\n",
      " ..., \n",
      " [ 10.   11.6]\n",
      " [ 10.   11.6]\n",
      " [ 10.   11.6]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Concatenate, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "PH = 5\n",
    "\n",
    "def readData(filename):\n",
    "    EntryData = []\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    A1c_data = []\n",
    "    DM_data = []\n",
    "    AD_data = []\n",
    "    \n",
    "    tmp_x = []\n",
    "    tmp_y = []\n",
    "    tmp_A1c = []\n",
    "    tmp_DM = []\n",
    "    tmp_AD = []\n",
    "    \n",
    "    with open(filename,'r') as f:\n",
    "        for line in f:\n",
    "            g, m = line.replace('\\n','').split(',')\n",
    "            EntryData.append([float(g),float(m)])\n",
    "            \n",
    "    df = pd.Series(EntryData)\n",
    "    A1c, DM = df[0]   \n",
    "    \n",
    "    while True:\n",
    "        for i in df[1:8]:\n",
    "            tmp_x.append([i[0],i[1]])\n",
    "            \n",
    "        tmp_y.append(df[8 + (PH/5)][0])\n",
    "        #tmp_y.append(df[8 + (PH/5)][1])\n",
    "        tmp_A1c.append(float(A1c))\n",
    "        tmp_DM.append(float(DM))\n",
    "        \n",
    "        tmp_AD.append(float(A1c))\n",
    "        tmp_AD.append(float(DM))\n",
    "\n",
    "        x_data.append(tmp_x)\n",
    "        y_data.append(tmp_y)\n",
    "        A1c_data.append(tmp_A1c)\n",
    "        DM_data.append(tmp_DM)\n",
    "        AD_data.append(tmp_AD)\n",
    "\n",
    "        tmp_x = []\n",
    "        tmp_y = []\n",
    "        tmp_A1c = []\n",
    "        tmp_DM = []\n",
    "        tmp_AD = []\n",
    "        \n",
    "        df = df.shift(-1)        \n",
    "        if type(df[8+(PH/5)]) == float:\n",
    "            break\n",
    "    #if(len(x_data[-1]) != 7):\n",
    "       #xSize = 7-len(x_data[-1])\n",
    "       #for i in range(xSize):\n",
    "           #x_data[-1].append(0.0)\n",
    "    #if(len(y_data[-1])!=1):\n",
    "       #y_data[-1].append(0.0)\n",
    "\n",
    "    x_data = np.asarray(x_data)\n",
    "    y_data = np.asarray(y_data)\n",
    "    A1c_data = np.asarray(A1c_data)\n",
    "    DM_data = np.asarray(DM_data)\n",
    "    AD_data = np.asarray(AD_data)\n",
    "    data = [x_data,y_data,A1c_data,DM_data,AD_data]\n",
    "    return data\n",
    "    \n",
    "filename = os.listdir(\"sch\")\n",
    "#print(filename)\n",
    "train_data_name = []\n",
    "test_data_name = []\n",
    "\n",
    "for fn in filename:\n",
    "    if fn.find(\"test\") != -1:\n",
    "        test_data_name.append(fn)\n",
    "    elif fn.find(\"train\") != -1:\n",
    "        train_data_name.append(fn)\n",
    "\n",
    "train_x_data = []\n",
    "train_y_data = []\n",
    "train_A1c_data = []\n",
    "train_DM_data = []\n",
    "train_AD_data = []\n",
    "\n",
    "test_x_data = []\n",
    "test_y_data = []\n",
    "test_A1c_data = []\n",
    "test_DM_data = []\n",
    "test_AD_data = []\n",
    "\n",
    "for fn in train_data_name:\n",
    "    if fn.find(\"885633\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    elif fn.find(\"365303\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    else:\n",
    "        print(str(fn))\n",
    "        x,y,A1c,DM,AD = readData(\"sch/\"+str(fn))\n",
    "        train_x_data.append(x)\n",
    "        train_y_data.append(y)\n",
    "        train_A1c_data.append(A1c)\n",
    "        train_DM_data.append(DM)\n",
    "        train_AD_data.append(AD)\n",
    "        \n",
    "for fn in test_data_name:\n",
    "    print(str(fn))\n",
    "    if fn.find(\"885633\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    elif fn.find(\"365303\") != -1:\n",
    "        print(fn+\"제외\")\n",
    "    else:\n",
    "        x,y,A1c,DM,AD = readData(\"sch/\"+str(fn))\n",
    "        test_x_data.append(x)\n",
    "        test_y_data.append(y)\n",
    "        test_A1c_data.append(A1c)\n",
    "        test_DM_data.append(DM)\n",
    "        test_AD_data.append(AD)\n",
    "\n",
    "######## Learning ########\n",
    "#print(train_y_data[0]) #환자 1명의 y, [[y값], ...]\n",
    "#print(train_A1c_data[0]) #환자 1명의 A1c, [[A1c], ...]\n",
    "#print(train_x_data[0]) #환자 1명의 x, [[혈당, 식사], ...]\n",
    "print(train_AD_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FFNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ba57ff03ccae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFFNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FFNN' is not defined"
     ]
    }
   ],
   "source": [
    "inputA = Input(shape=(7,2))\n",
    "inputB = Input(shape=(2,))\n",
    "x = LSTM(25,activation=\"linear\")(inputA)\n",
    "x = Dense(1)(x)\n",
    "#x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "y = Dense(10, activation=\"relu\")(inputB)\n",
    "y = Dense(1)(y)\n",
    "#y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "#added = keras.layers.Add()([x,y])\n",
    "combined = concatenate([x, y])\n",
    "\n",
    "z = FFNN(10, activation=\"linear\")(combined)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "#model = Model(inputs=inputA ,outputs=x)\n",
    "model = Model(inputs=[inputA,inputB] ,outputs=z)\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "##### Model fit. Error #####\n",
    "\n",
    "for i in range(len(train_x_data)):\n",
    "    model.fit([train_x_data[i],train_AD_data[i]],train_y_data[i],epochs=10,batch_size=10)\n",
    "    break\n",
    "\n",
    "'''\n",
    "for i in range(len(train_x_data)):\n",
    "    model.fit(train_x_data[i],train_y_data[i],epochs=10,batch_size=10)\n",
    "    break; \n",
    "'''\n",
    "'''\n",
    "for i in range(len(train_x_data)):\n",
    "    for k in range(len(train_x_data[i])):\n",
    "        model.fit(train_x_data[i][k],[train_A1c_data[i][k]],[train_y_data[i][k]],epochs=10)\n",
    "    break;           \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [array([[[ 178.,    0.],\n        [ 182.,    0.],\n        [ 180.,    0.],\n        ..., \n        [ 178.,    0.],\n        [ 177.,    0.],\n        [ 176.,    0.]],\n\n       [[ 182.,    0.],\n        [ 180.,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7745d611fe96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_A1c_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/anaconda3/envs/forest/lib/python3.4/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [array([[[ 178.,    0.],\n        [ 182.,    0.],\n        [ 180.,    0.],\n        ..., \n        [ 178.,    0.],\n        [ 177.,    0.],\n        [ 176.,    0.]],\n\n       [[ 182.,    0.],\n        [ 180.,..."
     ]
    }
   ],
   "source": [
    "RMSE = 0\n",
    "\n",
    "for p in range(len(train_x_data)):\n",
    "    y_pred = model.predict([train_x_data[p],train_A1c_data[p]])\n",
    "    MSE = 0\n",
    "    size = 0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        #print(\"예측값 : \"+ str(y_pred[i]) + \"    실제값 : \"+ str(train_y_data[p][i]))\n",
    "        MSE = MSE + pow(y_pred[i][0]-train_y_data[p][i][0],2)\n",
    "        size = size + 1\n",
    "    MSE = math.sqrt(float(MSE/size))\n",
    "    RMSE = RMSE + MSE\n",
    "    print(str(p) + '번째 환자 RMSE : ' + str(MSE))\n",
    "\n",
    "RMSE = float(RMSE/len(train_x_data))\n",
    "print(RMSE)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
